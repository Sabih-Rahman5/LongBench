{"_id": "66ebed525a08c7b9b35e1cb4", "domain": "Single-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "When Miller tried to answer the question \"should we read Heart of Darkness?\", he put forward a new concept for read \"but perform a reading in the strong\nsense, an active responsible response that renders justice to a book by generating more language in its turn\". However, he actually laid an implied premise for his argument, which one of the followings is true?", "choice_A": "Each must read for himself or herself and testify anew.", "choice_B": "Readers must reach a high standrad to some degree.", "choice_C": "It is the readers' obligation to get the \"truth\" from the primary narrator.", "choice_D": "The performative interpretation of language transforms what it interprets.", "answer": "B", "context": "Chapter Five\nJOSEPH CONRAD:\nSHOULD WE READ\nHEART OF DARKNESS}\nThe inaccessible incites from its place of hiding.\n\n\nSHOULD WE READ Heart of Darkness} May we read it? Must we read it?\nOr, on the contrary, ought we not to read it or allow our students and the\npublic in general to read it? Should every copy be taken from all the\nshelves and burned? What or who gives us the authority to make a deci-\nsion about that? Who is this \"we\" in whose name I speak? What commu-\nnity forms that \"we\" ? Nothing could be more problematic than the bland\nappeal to some homogeneous authoritative body, say professors of En-\nglish literature everywhere, capable of deciding collectively whether \"we\"\nshould read Heart of Darkness. By \"read\" I mean not just run the words\npassively through the mind's ear, but perform a reading in the strong\nsense, an active responsible response that renders justice to a book by\ngenerating more language in its turn, the language of attestation, even\nthough that language may remain ", "response": "The correct answer is (D) The performative interpretation of language transforms what it interprets.", "pred": "D", "judge": false}
{"_id": "66ec0c4c821e116aacb1994a", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "easy", "length": "medium", "question": "Which of the following statements is correct?", "choice_A": "Both contractor data and data crawled from the Internet are used to train VPT agents to model state-action pairs.", "choice_B": "All machine learning methods involved in the two articles are related to neural network deep learning.", "choice_C": "Both voyager and VPT control Minecraft agents by predicting the actions of simulated mouse and keyboard operations in each given state.", "choice_D": "VPT's modeling of action space is approximate rather than precise.", "answer": "D", "context": "Video PreTraining (VPT): Learning to Act by\nWatching Unlabeled Online Videos\nAbstract\nPretraining on noisy, internet-scale datasets has been heavily studied as a technique\nfor training models with broad, general capabilities for text, images, and other\nmodalities.1–6 However, for many sequential decision domains such as robotics,\nvideo games, and computer use, publicly available data does not contain the labels\nrequired to train behavioral priors in the same way. We extend the internet-scale\npretraining paradigm to sequential decision domains through semi-supervised\nimitation learning wherein agents learn to act by watching online unlabeled videos.\nSpeciﬁcally, we show that with a small amount of labeled data we can train an\ninverse dynamics model accurate enough to label a huge unlabeled source of online\ndata – here, online videos of people playing Minecraft – from which we can then\ntrain a general behavioral prior. Despite using the native human interface (mouse\nand keyboard at 20Hz)", "response": "The correct answer is (A).", "pred": "A", "judge": false}
{"_id": "66ed875e821e116aacb2023e", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "medium", "question": "On what issue do Wang Hui and Badiou have similar views?", "choice_A": "Fixed identities should be transformed into dynamic identities", "choice_B": "The problem with contemporary politics is devaluation and neutralization", "choice_C": "The problem with contemporary politics is cultural relativism", "choice_D": "Ideology promotes the formation of subjective consciousness", "answer": "A", "context": "SAINT PAUL \n\n\nSAINT PAUL \nThe Foundation of \nUniversalism \nAlain Badiou \nTranslated by Ray Brassier \nSTANFORD UNIVERSITY PRESS \nSTANFORD, CALIFORNIA \n\n\nStanford University Press \nStanford, California \nwww.sup.org \n© 2003 by the Board of \nTrustees of the Leland Stanford Junior University. All \nrights reserved. \nOriginally published as Saint PauL: La \nfondation de L'universaLisme, © 1997 by \nPresses Universitaires de France \nAssistance for the translation was provided by the French Ministry of Culture. \nPrinted in the United States of America on acid-free, archival-qualiLY paper. \nLibrary of Congress Cataloging-in-Publication Data \nBadiou, Alain. \n[Saint Paul. English] \nSaint Paul: the foundation of universalism / Alain Badiou; translated by Ray \nBrassier. \np. cm.-(Cultural memory in the present) \nISBN 0-8047-4470-X (cloth: aile. paper)-ISBN 0-8047-4471-8 (alk. paper) \n1. Paul, the Apostle, Saint. \n2. Bible N.T. Epistles ofPaul-Criticisl11, inter-\npretation, etc. \n3. Universalism-Biblica", "response": "The correct answer is (B) The problem with contemporary politics is devaluation and neutralization.", "pred": "B", "judge": false}
{"_id": "66f599ef821e116aacb34099", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "Which of the following descriptions is correct?", "choice_A": "Both StereoSet and CrowS-Pairs used word-filling testing methods to detect the anti-stereotype ability of the model and obtained the model ability score by calculating the proportion of choices that included the stereotype option.", "choice_B": "ETHOS and StereoSet both added irrelevant options in their testing, while CrowS-Pairs, although not providing irrelevant options in the test set, did not affect the test results due to the high probability of the model predicting irrelevant content at the completion position.", "choice_C": "ETHOS requires the model to give a yes or no answer to whether a statement is harmful", "choice_D": "The three articles all involve the detection of biases in the following areas of the model: race, religion, and sexism", "answer": "B", "context": "CrowS-Pairs: A Challenge Dataset for Measuring Social Biases\nin Masked Language Models\nAbstract\nWarning: This paper contains explicit state-\nments of offensive stereotypes and may be\nupsetting.\nPretrained\nlanguage\nmodels,\nespecially\nmasked language models (MLMs) have seen\nsuccess across many NLP tasks.\nHowever,\nthere is ample evidence that they use the\ncultural biases that are undoubtedly present\nin the corpora they are trained on, implicitly\ncreating harm with biased representations. To\nmeasure some forms of social bias in language\nmodels against protected demographic groups\nin the US, we introduce the Crowdsourced\nStereotype Pairs benchmark (CrowS-Pairs).\nCrowS-Pairs has 1508 examples that cover\nstereotypes dealing with nine types of bias,\nlike race, religion, and age. In CrowS-Pairs a\nmodel is presented with two sentences: one\nthat is more stereotyping and another that\nis less stereotyping.\nThe data focuses on\nstereotypes about historically disadvantaged\ngroups and contrasts them wi", "response": "The correct answer is (B).", "pred": "B", "judge": true}
{"_id": "66eefe85821e116aacb228dc", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "These are two articles about grassland simulation. The first article is \"Responsive Real Time Grass Rendering for General 3D Scenes\", and the second article is \"CWD Sim: Real Time Simulation on Grass Swaying with Controllable Wind Dynamics”. Which of the following statements regarding the differences in content between the two articles is incorrect?", "choice_A": "In the first article, some unimportant leaves were removed to save performance, and the second article use LOD (detail level) algorithm for performance optimization.", "choice_B": "The second article emphasizes the undulation of the grass by using color changes in different bent states, while the first article does not use this method.", "choice_C": "The first article calculates leaf displacement using natural elements as coefficients, while the second article uses fluid simulation to calculate wind forces that bend the leaves.", "choice_D": "The first article can simulate wind in a certain direction or specific wind source, while the second article can simulate the effects of wind fields in multiple directions on grasslands and allow users to freely customize wind effects.", "answer": "A", "context": "Responsive Real-Time Grass Rendering for General 3D Scenes\nKlemens Jahrmann∗\nMichael Wimmer†\nTU Wien\nTU Wien\nFigure 1: This ﬁgure shows an example of our rendering technique. The collision reaction is visible at the trail of the bowling ball. The right\nside is rendered in wireframe mode to show the accuracy of our occlusion culling method.\nAbstract\nGrass plays an important role in most natural environments. Most\ninteractive applications use image-based techniques to approximate\nﬁelds of grass due to the high geometrical complexity, leading to vi-\nsual artifacts. In this paper, we propose a grass-rendering technique\nthat is capable of drawing each blade of grass as geometrical ob-\nject in real time. Accurate culling methods together with an adapt-\nable rendering pipeline ensure that only the blades of grass that are\nimportant for the visual appearance of the ﬁeld of grass are ren-\ndered. In addition, we introduce a physical model that is evaluated\nfor each blade of grass. This enables t", "response": "The correct answer is (B).", "pred": "B", "judge": false}
{"_id": "66f167c3821e116aacb274f4", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "medium", "question": "Both ‘Sport and Secessionism’ and ‘Discrimination, Sport, and Nation Building among Indonesian Chinese in the 1950s’ explore how sports are manipulated to serve political or nationalistic agendas. Considering the contexts and challenges in both texts, which of the following “most accurately reflects” the deeper socio-political tension that arises when sports are used as a means of unifying diverse groups?", "choice_A": "The use of sports to promote national unity often leads to failure when minority groups are expected to adopt the dominant cultural identity, causing internal friction.", "choice_B": "While sports aim to unify, they often fail when minority groups are pressured to align with the dominant national identity, leading to internal dissent and resistance.", "choice_C": "The use of sports to project national unity often fails when minority groups are expected to assimilate into a pre-existing national identity, leading to increased internal resistance.", "choice_D": "Efforts to use sports for national unity are hindered when minority groups are required to adopt the majority identity, resulting in increased opposition and failure to achieve true unity.", "answer": "C", "context": "1\n2\n3\n4\n5\nContents\nNotes on contributors\nIntroduction\nMARIANN VACZI AND ALAN BAIRNER\nSport and the unfinished Irish Revolution\nALAN BAIRNER\nSport and secessionism in Scotland\nSTUART WHIGHAM\nSpeaking for Wales: sport and secessionism in a small nation\nJOHN HARRIS\nA game of lions and devils: sport as a driver and inhibitor of\nFlemish secession\nARNOUT GEERAERT, EDITH DRIESKENS AND BART\nMADDENS\nThe tug of war of nationalisms: agonic sports for Basque–Spanish\nrelations\nMARIANN VACZI\n\n\n6\n7\n8\n9\n10\n11\n12\n13\n14\nVisions of building, specters of collapse: alternative routes to\nsecessionism in Catalonia\nMARIANN VACZI\nFootball in Corsica: from the pride of being French to the desire\nnot to be?\nDIDIER REY\nLiving through defeat: Hungarian–Romanian relations through\nSzekler hockey\nMARIANN VACZI\nTwo styles of engagement: Kurds and football in Turkey\nÖMER TURAN\nNarratives of nationalist politics and sport in Sindh\nSAHAR GUL AND ALAN BAIRNER\nAssembling the diasporic nation: Kabylia at the CONIFA World\nFo", "response": "The correct answer is (B).", "pred": "B", "judge": false}
{"_id": "66ebc4af5a08c7b9b35dede0", "domain": "Single-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "Based on the passage, which of the following statements about the DigiRL framework's interaction with the emulator is correct?", "choice_A": "In the Web Shopping subsets, DigiRL increased by 3.6% compared to Filtered BC, while in the General subsets it was about 10%.", "choice_B": "The all possible actions for the agent in the DigiRL framework include tapping and swiping on the screen using normalized (x, y) coordinates and typing variable-length text inputs.", "choice_C": "The automatic curriculum in DigiRL adjusts the instruction-level value function to filter out easy tasks, allowing the agent to focus solely on tasks it has not yet encountered during training.", "choice_D": "The cross-entropy loss function is applied in DigiRL exclusively to the policy network, avoiding its use in the training of value functions to prevent overfitting in the model.", "answer": "A", "context": "DigiRL: Training In-The-Wild Device-Control\nAgents with Autonomous Reinforcement Learning\nAbstract\nTraining corpuses for vision language models (VLMs) typically lack sufficient\namounts of decision-centric data. This renders off-the-shelf VLMs sub-optimal\nfor decision-making tasks such as in-the-wild device control through graphical\nuser interfaces (GUIs). While training with static demonstrations has shown\nsome promise, we show that such methods fall short for controlling real GUIs\ndue to their failure to deal with real world stochasticity and non-stationarity not\ncaptured in static observational data. This paper introduces a novel autonomous\nRL approach, called DigiRL, for training in-the-wild device control agents through\nfine-tuning a pre-trained VLM in two stages: offline RL to initialize the model,\nfollowed by offline-to-online RL. To do this, we build a scalable and parallelizable\nAndroid learning environment equipped with a VLM-based evaluator and develop\na simple yet effective ", "response": "The correct answer is (B).", "pred": "B", "judge": false}
{"_id": "66f95126bb02136c067c5070", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "easy", "length": "short", "question": "Compared with lets verify step by step, which of the following points is not included in the improvement of math-shepherd?", "choice_A": "math-shepherd uses reinforcement learning to improve model capabilities and provides specific training methods.", "choice_B": "math-shepherd proposes a method for automatically labeling PRM, which simplifies the manual labeling part in the lets verify article.", "choice_C": "math-shepherd is compared with the Self-consistency method, while the lets verify article does not compare.", "choice_D": "math-shepherd introduces two methods of estimating rewards, hard and soft.", "answer": "C", "context": "Let’s Verify Step by Step\nOpenAI\nAbstract\nIn recent years, large language models have greatly improved in their\nability to perform complex multi-step reasoning.\nHowever, even state-\nof-the-art models still regularly produce logical mistakes. To train more\nreliable models, we can turn either to outcome supervision, which provides\nfeedback for a final result, or process supervision, which provides feedback\nfor each intermediate reasoning step. Given the importance of training\nreliable models, and given the high cost of human feedback, it is impor-\ntant to carefully compare the both methods. Recent work has already\nbegun this comparison, but many questions still remain. We conduct our\nown investigation, finding that process supervision significantly outper-\nforms outcome supervision for training models to solve problems from the\nchallenging MATH dataset. Our process-supervised model solves 78% of\nproblems from a representative subset of the MATH test set. Additionally,\nwe show that active", "response": "The correct answer is (C).", "pred": "C", "judge": true}
{"_id": "66ee4c55821e116aacb21596", "domain": "Single-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "long", "question": "Which of the following is not a contributing factor to the Chinese Rites Controversy?", "choice_A": "The Council of Trent was held, and the power of the Pope was expanded", "choice_B": "Disputes among Jesuits over the Chinese translation of God", "choice_C": "The speed of Chinese teaching was accelerated, and missionaries did not fully understand Chinese thoughts and classics", "choice_D": "The believers formed spontaneous associations, and the missionaries lost control of these associations", "answer": "D", "context": "journey to the east\n\n\n\n\nJourney to the East\nF\nThe Jesuit Mission to China,\n1579–1724\nLiam Matthew Brockey\nthe belknap press of\nharvard university press\nCambridge, Massachusetts\nLondon, England\n\n\n\n\nFor J.S.A.E.\n\n\n\n\nContents\nPreface\nix\nNote on Translations and Orthography\nxi\nIntroduction\n1\npart i\nCharting the Course\n1\nAn Uneasy Foothold\n25\n2\nIn the Shadow of Greatness\n57\n3\nWitnesses to Armageddon\n92\n4\nThe Problem of Success\n125\n5\nBetween Tolerance and the Intolerable\n164\npart ii\nBuilding the Church\n6\nIn the Apostles’ Classroom\n207\n7\nLearning the Language of Birds\n243\n8\nThe Business of Conversion\n287\n9\nA Good Method and Order\n328\n10\nBrothers of Passion and Mercy\n366\nConclusion\n403\nBibliographic Note\n423\nNotes\n427\nIllustration Credits\n479\nIndex\n481\n\n\n\n\nPreface\nLike the chain of events recounted in the chapters that follow, this book\nstarted with a journey. But in contrast to the voyages of missionaries four\ncenturies ago, mine was a journey to the West. Although I did not know\nat the time ", "response": "The correct answer is (B).", "pred": "B", "judge": false}
{"_id": "66f55d66821e116aacb33734", "domain": "Single-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "Regarding the experimental methods in this article, the following statement is correct:", "choice_A": "For the homeowners of these houses, the author only used machine learning methods to analyze their account profile pictures and determine characteristics such as race, gender, and age.", "choice_B": "This article employs a randomized trial method, selecting 10 experimental areas and creating 20 Airbnb test accounts to randomly book houses listed as \"available\" on the website eight weeks in advance.", "choice_C": "The author categorized homeowners into six major groups based on their different responses, focusing primarily on those landlords who requested more information from tenants.", "choice_D": "The author collected past guest reviews from homeowners' web pages to ensure the validity of the experiment.", "answer": "D", "context": "American Economic Journal: Applied Economics 2017, 9(2): 1–22 \nhttps://doi.org/10.1257/app.20160213\n1\nRacial Discrimination in the Sharing Economy: \nEvidence from a Field Experiment†\nBy Benjamin Edelman, Michael Luca, and Dan Svirsky*\nIn an experiment on Airbnb, we find that applications from guests \nwith distinctively African American names are 16 percent less likely \nto be accepted relative to identical guests with distinctively white \nnames. Discrimination occurs among landlords of all sizes, includ-\ning small landlords sharing the property and larger landlords with \nmultiple properties. It is most pronounced among hosts who have \nnever had an African American guest, suggesting only a subset of \nhosts discriminate. While rental markets have achieved significant \nreductions in discrimination in recent decades, our results sug-\ngest that Airbnb’s current design choices facilitate discrimination \nand raise the possibility of erasing some of these civil rights gains. \n(JEL C93, J15, L83", "response": "The correct answer is (B).", "pred": "B", "judge": false}
{"_id": "66f2adaf821e116aacb2aca9", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "long", "question": "In both The Varieties of Grounded Theory and Advancing Grounded Theory with Mixed Methods, the authors examine the philosophical and practical implications of integrating grounded theory with other methodologies. Considering the flexibility of grounded theory and the structured nature of mixed methods, what is the most nuanced challenge that researchers face when attempting to synthesize these two approaches for theory development?", "choice_A": "The combination of grounded theory and mixed methods often requires researchers to compromise on theoretical sensitivity, as mixed methods demand structured variables that can hinder emergent data.", "choice_B": "The synthesis of grounded theory and mixed methods often forces researchers to compromise on theoretical sensitivity, as mixed methods demand predefined categories that may not align with emergent theories.", "choice_C": "The challenge is balancing the emergent flexibility of grounded theory with the predefined coding frameworks of mixed methods, making it difficult to preserve theoretical sensitivity.", "choice_D": "The difficulty arises when researchers attempt to align grounded theory's emergent coding with the structured variables of mixed methods, which can dilute the focus on theoretical sensitivity.", "answer": "B", "context": "THE VARIETIES \nOF GROUNDED \nTHEORY\n\n\nIn 1976 SAGE published a series of short ‘university papers’, which led to the \npublication of the QASS series (or the ‘little green books’ as they \nbecame known to researchers). More than 40 years since the release of \nthe first ‘little green book’, SAGE is delighted to offer a new series of swift, \nshort and topical pieces in the ever-growing digital environment.\nSAGE Swifts offer authors a new channel for academic research with the \nfreedom to deliver work outside the conventional length of journal articles. \nThe series aims to give authors speedy access to academic audiences \nthrough digital first publication, space to explore ideas thoroughly, yet at a \nlength which can be readily digested, and the quality stamp and reassurance\nof peer-review. \nswifts\nsage\n\n\nswifts\nsage\nTHE VARIETIES \nOF GROUNDED \nTHEORY\nANTONY BRYANT\n\n\nSAGE Publications Ltd\n1 Oliver’s Yard\n55 City Road\nLondon EC1Y 1SP\nSAGE Publications Inc.\n2455 Teller Road\nThousand Oaks, Cali", "response": "The correct answer is (C).", "pred": "C", "judge": false}
{"_id": "66ebee0a5a08c7b9b35e1d05", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "In the Phidias model, the loss function for reference-augmented multi-view diffusion is expressed as:\n\\[\nL = \\mathbb{E}{t,\\epsilon \\sim \\mathcal{N}(0,1)} \\left[ \\lVert \\epsilon - \\epsilon\\theta(x_t, t, c_{\\text{image}}, c_{\\text{ref}}) \\rVert^2 \\right]\n\\]\nwhere:\n\t•\t \\epsilon_\\theta  is the predicted noise at each timestep.\n\t•\t x_t  is the noisy image at timestep  t .\n\t•\t c_{\\text{image}}  is the conditioning on the input concept image.\n\t•\t c_{\\text{ref}}  is the conditioning on the 3D reference model (expressed as canonical coordinate maps, or CCMs).\nThe Meta-ControlNet in Phidias modifies the strength of the conditioning based on the alignment between the reference and the concept image.\nGiven this architecture, how does Meta-ControlNet influence the gradients during backpropagation, particularly in handling misaligned references during the training process, and why is this modulation essential to improving generalization in 3D generation?", "choice_A": "Meta-ControlNet introduces alignment-weighted gradients where the similarity between the 3D reference and the concept image (measured by cosine similarity) is used to dynamically scale the gradients in backpropagation. If the reference and image are misaligned, it reduces the gradient contribution from the reference, preventing the model from fitting erroneous geometrical details. This modulation happens across almost all noise levels to guarantee that both global and local features are learned without overfitting to poor references.", "choice_B": "Meta-ControlNet applies time-dependent gradient scaling, where at higher timesteps (when the noise level is higher), the reference model is given more influence on gradient updates through increased weight on its canonical coordinate maps (CCMs). This forces the model to hallucinate missing parts of the 3D object when the reference is not closely aligned with the concept image. As the noise level declines, the model shifts to rely more on the image, prioritizing the image’s geometric integrity during backpropagation at later stages.", "choice_C": "Meta-ControlNet incorporates an auxiliary loss term based on the L2 distance between the reference and concept image features. This term is minimized during backpropagation to encourage the model to forcefully align the concept image and reference model even when there is a mismatch. The result is stronger gradients for references that are dissimilar, which improves the ability of the model to learn generalizable shape priors from misaligned references.", "choice_D": "Meta-ControlNet modulates multi-scale feature alignment using a learned weighting matrix that dynamically scales the gradients according to both the noise level and the feature similarity between the reference and the concept image. At high noise levels, the matrix suppresses the gradients from the reference model to avoid distorting the overall geometry, while at low noise levels, it increases the gradient influence from the reference to refine local details. This allows for controlled generation based on the level of alignment across different noise stages of diffusion.", "answer": "D", "context": "PHIDIAS: A GENERATIVE MODEL FOR CREATING 3D\nCONTENT FROM TEXT, IMAGE, AND 3D CONDITIONS\nWITH REFERENCE-AUGMENTED DIFFUSION\n\nABSTRACT\nIn 3D modeling, designers often use an existing 3D model as a reference to create\nnew ones. This practice has inspired the development of Phidias, a novel gen-\nerative model that uses diffusion for reference-augmented 3D generation. Given\nan image, our method leverages a retrieved or user-provided 3D reference model\nto guide the generation process, thereby enhancing the generation quality, gen-\neralization ability, and controllability. Our model integrates three key compo-\nnents: 1) meta-ControlNet that dynamically modulates the conditioning strength,\n2) dynamic reference routing that mitigates misalignment between the input image\nand 3D reference, and 3) self-reference augmentations that enable self-supervised\ntraining with a progressive curriculum. Collectively, these designs result in signif-\nicant generative improvements over existing methods. Phidias", "response": "The correct answer is (A).", "pred": "A", "judge": false}
{"_id": "66f14c70821e116aacb271ee", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "What is the difference between the datasets of the two papers?", "choice_A": "The data set in DAIR-V2X includes actual measured data of V2V and V2I, while the data set in V2X-Sim also includes V2V and V2I, but it is simulated data.", "choice_B": "The dataset in DAIR-V2X is measured data and takes into account the time asynchrony caused by communication, while the dataset in V2X-Sim does not take this into account.", "choice_C": "Neither the DAIR-V2X nor the V2X-Sim datasets consider the problem of posture errors.", "choice_D": "DAIR-V2X is the first measured dataset that includes both V2V and V2I。", "answer": "C", "context": "DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative\n3D Object Detection\nHaibao Yu1, Yizhen Luo1,3, Mao Shu2, Yiyi Huo1,4, Zebang Yang1,3, Yifeng Shi2, Zhenglong Guo2,\nHanyu Li2, Xing Hu2, Jirui Yuan1, Zaiqing Nie1*\n1Institute for AI Industry Research(AIR), Tsinghua University\n2 Baidu Inc. 3 Department of Computer Science and Technology, Tsinghua University\n4 University of Chinese Academy of Science\n{yuhaibao@air.,luoyz18@mails.,yzb19@mails.,yuanjirui@air.,zaiqing@air.}tsinghua.edu.cn,\n{shumao,shiyifeng,guozhenglong,lihanyu02,huxing}@baidu.com, huoyiyi18@mails.ucas.ac.cn\nAbstract\nAutonomous driving faces great safety challenges for a\nlack of global perspective and the limitation of long-range\nperception capabilities.\nIt has been widely agreed that\nvehicle-infrastructure cooperation is required to achieve\nLevel 5 autonomy. However, there is still NO dataset from\nreal scenarios available for computer vision researchers\nto work on vehicle-infrastructure cooperation-relat", "response": "The correct answer is (D) DAIR-V2X is the first measured dataset that includes both V2V and V2I.", "pred": "D", "judge": false}
{"_id": "66f2cacb821e116aacb2ba50", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "medium", "question": "According to the two articles above, which of the following statements is incorrect?", "choice_A": "Using the following prompt to generate a specific molecular will get a better performance on molT5 than asking GPT-4:\n\"The molecule is a sulfonated xanthene dye of absorption wavelength 573 nm and emission wavelength 591 nm. It has a role as a fluorochrome.\"", "choice_B": "Using the following prompt to predict protein-molecule affinity will get a better performance on GPT-4 than asking molT5:\n\"SMILES: COC1=NC=C(C=C1)COC2=C(C=C(C=C2)CN3C=NC4=C3N=CC(=C4)C5=NN=C(O5)C6CCNCC6)OC, FASTA: MSSWIRWHGPAMARLWGFCWLVVGFWRAAFACPTSCKCSA...TLLQNLAKASPVYLDILG. You need to calculate the binding affinity score.\"", "choice_C": "When given few-shot examples, GPT-4 can produce results almost comparable to existing deep learning models on the Drug-Target Affinity (DTA) task.", "choice_D": "GPT-4 demonstrates a solid understanding of key information in evolutionary biology.", "answer": "C", "context": "The Impact of Large Language Models on Scientific Discovery:\na Preliminary Study using GPT-4\nMicrosoft Research AI4Science\nMicrosoft Azure Quantum\nllm4sciencediscovery@microsoft.com\nNovember, 2023\nAbstract\nIn recent years, groundbreaking advancements in natural language processing have culminated in the\nemergence of powerful large language models (LLMs), which have showcased remarkable capabilities across a\nvast array of domains, including the understanding, generation, and translation of natural language, and even\ntasks that extend beyond language processing. In this report, we delve into the performance of LLMs within\nthe context of scientific discovery/research, focusing on GPT-4, the state-of-the-art language model. Our\ninvestigation spans a diverse range of scientific areas encompassing drug discovery, biology, computational\nchemistry (density functional theory (DFT) and molecular dynamics (MD)), materials design, and partial\ndifferential equations (PDE).\nEvaluating GPT-4 on scien", "response": "The correct answer is (B).", "pred": "B", "judge": false}
{"_id": "66eae4de5a08c7b9b35dd12d", "domain": "Single-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "Which kind of ability is not mentioned in the essay?", "choice_A": "Segment and label objects within the scene using SoM and represent the functional parts by vectors.", "choice_B": "Understand and execute higher level and multi-step instruction.", "choice_C": "Process accurate coordinates of object parts generated by VLMs to form a 3D grounding.", "choice_D": "Generate the appropriate 6-DoF grasp pose for the specified objects of interest and show a higher success rate than Voxposer.", "answer": "C", "context": "CoPa: General Robotic Manipulation through\nSpatial Constraints of Parts with Foundation Models\nInitial Observation\nHammer the nail.\nTask-Oriented\nGrasping\nModule\nObservation after Grasping\nPost-Grasp Poses\n{𝑃\n1, 𝑃2, … , 𝑃𝑁}\nPose 𝑃\n1\nPose 𝑃2\n“Find scissors”\n“Press button”\n“Open drawer”\n“Pour water”\n“Put eraser into drawer”\n“Insert flower into vase”\n“Put glasses onto shelf”\n“Put spoon into cup”\n“Sweep nuts”\nTask-Aware\nMotion Planning\nModule\nFig. 1: Overview. We present CoPa, a novel framework that utilizes common sense knowledge embedded within VLMs\nfor robotic low-level control. Left. Our pipeline. Given an instruction and scene observation, CoPa first generates a grasp\npose through Task-Oriented Grasping Module (detailed in Fig. 3). Subsequently, a Task-Aware Motion Planning Module\n(detailed in Fig. 4) is utilized to obtain post-grasp poses. Right. Examples of real-world experiments. Boasting a fine-grained\nphysical understanding of scenes, CoPa can generalize to open-world scenarios, ", "response": "The correct answer is (C).", "pred": "C", "judge": true}
{"_id": "66ed364d821e116aacb1f47e", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "easy", "length": "medium", "question": "Which article dynamically models the temporal sequence of single-frame distribution functions and differs from other articles?", "choice_A": "Point-Supervised Video Temporal Grounding", "choice_B": "Probability Distribution Based Frame-supervised Language-driven Action Localization", "choice_C": "Mm - 2024 - Explicit Granularity and Implicit Scale Correspond.pdf", "choice_D": "D3G: Exploring Gaussian Prior for Temporal Sentence Grounding with Glance Annotation", "answer": "D", "context": "Video Moment Retrieval from Text Queries via\nSingle Frame Annotation\nFudan University, China\nygj@fudan.edu.cn\nABSTRACT\nVideo moment retrieval aims at finding the start and end times-\ntamps of a moment (part of a video) described by a given natural\nlanguage query. Fully supervised methods need complete temporal\nboundary annotations to achieve promising results, which is costly\nsince the annotator needs to watch the whole moment. Weakly\nsupervised methods only rely on the paired video and query, but\nthe performance is relatively poor. In this paper, we look closer\ninto the annotation process and propose a new paradigm called\n“glance annotation”. This paradigm requires the timestamp of only\none single random frame, which we refer to as a “glance”, within\nthe temporal boundary of the fully supervised counterpart. We\nargue this is beneficial because comparing to weak supervision,\ntrivial cost is added yet more potential in performance is provided.\nUnder the glance annotation setting, we pro", "response": "The correct answer is (D) D3G: Exploring Gaussian Prior for Temporal Sentence Grounding with Glance Annotation.", "pred": "D", "judge": true}
{"_id": "66f2c44e821e116aacb2b826", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "medium", "question": "Which of the following statements about Chroma and GPT-4 is incorrect?", "choice_A": "Both of Chroma and GPT-4 are capable of executing tasks pertinent to biological molecular processes.", "choice_B": "Chroma incorporates concepts from diffusion model, whereas GPT-4 is independent of any references to it.", "choice_C": "Like text-to-image diffusion models, Chroma can generate protein caption from its 1D sequence independently.", "choice_D": "Both of Chroma and GPT-4 have cited at least one common paper in their Reference section.", "answer": "C", "context": "GPT-4 Technical Report\nOpenAI∗\nAbstract\nWe report the development of GPT-4, a large-scale, multimodal model which can\naccept image and text inputs and produce text outputs. While less capable than\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance\non various professional and academic benchmarks, including passing a simulated\nbar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-\nbased model pre-trained to predict the next token in a document. The post-training\nalignment process results in improved performance on measures of factuality and\nadherence to desired behavior. A core component of this project was developing\ninfrastructure and optimization methods that behave predictably across a wide\nrange of scales. This allowed us to accurately predict some aspects of GPT-4’s\nperformance based on models trained with no more than 1/1,000th the compute of\nGPT-4.\n1\nIntroduction\nThis technical report presents GPT-4, a large multimodal model capa", "response": "The correct answer is (B).", "pred": "B", "judge": false}
{"_id": "66ee4287821e116aacb21258", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "These two articles both focused on mix-precision acceleration, especially involving FP16, in multigrid preconditioners. What are the differences between them?", "choice_A": "They use the same techniques, such as the scaling and solving methods, to apply FP16 in multigrid preconditioner. However, their evaluations were on different architectures with different implementations. The performance speedups of the work on CPU were more prominent than the work on GPU. But the conclusions were universal and not architecture-specific.", "choice_B": "Their scaling methods were different. The article \"Three-precision algebraic multigrid on GPUs\" showed the design and implementation of unstructured AMG for GPU. The guidelines and algorithms proposed in the other article were also applicable in unstructured scenarios and on GPU, but the evaluations were based on structured-specific multigrid on CPU.", "choice_C": "They are based on different types of multigrids. The article \"Three-precision algebraic multigrid on GPUs\" focused on unstructured AMG that is suitable for general problems. Still, it did not discuss details about its implementations, such as where the scaling is located in the whole multigrid procedure. The other article provided a comprehensive investigation including guidelines, algorithms, and implementations, but those discussions were restricted to structured-specific multigrid.", "choice_D": "They were on different hardware platforms, and had different software designs for multigrid algorithms. The article \"Three-precision algebraic multigrid on GPUs\" focused on unstructured multigrid on GPU, while the other article only showed algorithms, experiments and discussions on structured-specific multigrid on CPU. The conclusions on CPU were difficult to port to GPU.", "answer": "B", "context": "FP16 Acceleration in Structured Multigrid Preconditioner for\nABSTRACT\nHalf-precision hardware support is now almost ubiquitous. In con-\ntrast to its active use in AI, half-precision is less commonly em-\nployed in scientific and engineering computing. The valuable propo-\nsition of accelerating scientific computing applications using half-\nprecision prompted this study. Focusing on solving sparse linear\nsystems in scientific computing, we explore the technique of uti-\nlizing FP16 in multigrid preconditioners. Based on observations of\nsparse matrix formats, numerical features of scientific applications,\nand the performance characteristics of multigrid, this study formu-\nlates four guidelines for FP16 utilization in multigrid. The proposed\nalgorithm demonstrates how to avoid FP16 overflow through scal-\ning. A setup-then-scale strategy prevents FP16’s limited accuracy\nand narrow range from interfering with the multigrid’s numerical\nproperties. Another strategy, recover-and-rescale on the fl", "response": "The correct answer is (B).", "pred": "B", "judge": true}
{"_id": "66faac15bb02136c067c73f3", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "Regarding the comparison between these two articles, which of the following is correct?", "choice_A": "Both AndroidArena and B-moca have designed two types of tasks: single app tasks and multi app tasks. AndroidArena also includes tasks that restrict the use of a specific app.", "choice_B": "The testing method designed by B-moca is universal for text models, multimodal models, and video models, while Android Arena uses Deep-Q learning to train agents, which can be easily extended to multimodal models, although this article does not cover this aspect.", "choice_C": "AndroidArena's test standards focus on operation sequences, while B-moca focuses on execution results on the simulator. Specifically, the Task Reward of AndroidArena calculates the LCS between the standard answer and the model operation sequence, and adds them up weighted.", "choice_D": "Both AndroidArena and B-moca need to use real Android machines for testing.", "answer": "C", "context": "BENCHMARKING MOBILE DEVICE CONTROL AGENTS ACROSS DIVERSE CONFIGURATIONS\nJuyong Lee1\nTaywon Min2\nMinyong An3\nChangyeon Kim1\nKimin Lee1\n1KAIST\n2Seoul National University\n3Yonsei University\nABSTRACT\nDeveloping autonomous agents for mobile devices can significantly enhance user\ninteractions by offering increased efficiency and accessibility. However, despite\nthe growing interest in mobile device control agents, the absence of a commonly\nadopted benchmark makes it challenging to quantify scientific progress in this area.\nIn this work, we introduce B-MoCA: a novel benchmark designed specifically\nfor evaluating mobile device control agents. To create a realistic benchmark, we\ndevelop B-MoCA based on the Android operating system and define 60 common\ndaily tasks. Importantly, we incorporate a randomization feature that changes\nvarious aspects of mobile devices, including user interface layouts and language\nsettings, to assess generalization performance. We benchmark diverse agents,\nincluding ag", "response": "The correct answer is (C).", "pred": "C", "judge": true}
{"_id": "66ead7bd5a08c7b9b35dca7a", "domain": "Single-Document QA", "sub_domain": "Academic", "difficulty": "easy", "length": "long", "question": "Construct an uncertain variable with linear uncertainty distribution L(1,5)", "choice_A": "ξ(γ) = γ + 5", "choice_B": "ξ(γ) = 5γ + 1", "choice_C": "ξ(γ) = 5γ - 1", "choice_D": "ξ(γ) = 4γ + 1", "answer": "D", "context": "Uncertainty Theory\nFifth Edition\n\nContents\nPreface\nxi\n1\nIntroduction\n1\n1.1\nUrn Problems . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.2\nHow to Choose Your Mathematical Tool . . . . . . . . . . . .\n4\n2\nUncertain Measure\n7\n2.1\nUncertain Measure . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.2\nUncertainty Space\n. . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.3\nProduct Uncertain Measure . . . . . . . . . . . . . . . . . . .\n12\n2.4\nIndependence . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.5\nConditional Uncertain Measure . . . . . . . . . . . . . . . . .\n22\n2.6\nBibliographic Notes . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3\nUncertain Variable\n27\n3.1\nUncertain Variable . . . . . . . . . . . . . . . . . . . . . . . .\n27\n3.2\nUncertainty Distribution . . . . . . . . . . . . . . . . . . . . .\n30\n3.3\nInverse Uncertainty Distribution\n. . . . . . . . . . . . . . . .\n46\n3.4\nIndependence . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n3.5\nOperation", "response": "The correct answer is (B) ξ(γ) = 5γ + 1.", "pred": "B", "judge": false}
{"_id": "66f2ad2b821e116aacb2ac0f", "domain": "Multi-Document QA", "sub_domain": "Academic", "difficulty": "hard", "length": "short", "question": "Which is not among the improvements of the method in paper GeoBFN compared with paper BFN？", "choice_A": "Be able to process discrete input data like atom charges.", "choice_B": "Considering atom coordinates and types simultaneously.", "choice_C": "Equivariant to topological rotation of molecules.", "choice_D": "Adopt an early mode-seeking sampling strategy.", "answer": "A", "context": "Bayesian Flow Networks\n\nAbstract\nThis paper introduces Bayesian Flow Networks (BFNs), a new class of generative model in\nwhich the parameters of a set of independent distributions are modified with Bayesian inference\nin the light of noisy data samples, then passed as input to a neural network that outputs a\nsecond, interdependent distribution. Starting from a simple prior and iteratively updating\nthe two distributions yields a generative procedure similar to the reverse process of diffusion\nmodels; however it is conceptually simpler in that no forward process is required. Discrete and\ncontinuous-time loss functions are derived for continuous, discretised and discrete data, along\nwith sample generation procedures. Notably, the network inputs for discrete data lie on the\nprobability simplex, and are therefore natively differentiable, paving the way for gradient-based\nsample guidance and few-step generation in discrete domains such as language modelling. The\nloss function directly optimis", "response": "The correct answer is (A).", "pred": "A", "judge": true}
